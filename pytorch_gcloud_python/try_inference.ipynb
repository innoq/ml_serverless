{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import math\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from mllib import mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field = torch.load(\"./data/txt_field.pt\", pickle_module=dill)\n",
    "label_field = torch.load(\"./data/label_field.pt\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(txt_field.vocab)\n",
    "embedding_dim = 100\n",
    "n_hidden = 64\n",
    "n_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "tokenizer = mllib.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = txt_field.numericalize((\"keep voting for the goonies\", 1))\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_fields = [\n",
    "    ('ItemID', None),  # we dont need this, so no processing\n",
    "    ('Sentiment', label_field),  # process it as label\n",
    "    ('SentimentSource', None),  # we dont need this, so no processing\n",
    "    ('SentimentText', txt_field)  # process it as text\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds, valds = data.TabularDataset.splits(path='./data',\n",
    "                                            format='csv',\n",
    "                                            train='traindf.csv',\n",
    "                                            validation='valdf.csv',\n",
    "                                            fields=train_val_fields,\n",
    "                                            skip_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds),  # specify train and validation Tabulardataset\n",
    "                                            # batch size of train and validation\n",
    "                                            batch_sizes=(3, 3),\n",
    "                                            # on what attribute the text should be sorted\n",
    "                                            sort_key=lambda x: len(\n",
    "                                                x.SentimentText),\n",
    "                                            device=None,  # -1 mean cpu and 0 or None mean gpu\n",
    "                                            sort_within_batch=True,\n",
    "                                            repeat=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdl = data.BucketIterator.splits(datasets=[trainds],  # specify train and validation Tabulardataset\n",
    "                                            # batch size of train and validation\n",
    "                                            batch_sizes=(1, 1),\n",
    "                                            # on what attribute the text should be sorted\n",
    "                                            sort_key=lambda x: len(\n",
    "                                                x.SentimentText),\n",
    "                                            device=None,  # -1 mean cpu and 0 or None mean gpu\n",
    "                                            repeat=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(testdl))\n",
    "vars(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(valds))\n",
    "vars(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mllib.SimpleGRU(vocab_size, embedding_dim, n_hidden, n_out,\n",
    "                    txt_field.vocab.vectors, device=device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_state_dict(torch.load('./data/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.transpose(0,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text_in, pp_field, model):\n",
    "    tok = [[t.text.lower() for t in nlp(text_in)]]\n",
    "    print(tok)\n",
    "    X, lengths = pp_field.numericalize((tok, [1]))\n",
    "    r = model(X, lengths)\n",
    "\n",
    "    pos_certainty = (1 - math.exp(r.tolist()[0][0]))\n",
    "    if pos_certainty < 0.45:\n",
    "        print(f'{pos_certainty*100:2.4}% NO SENTIMENT for     {text_in}')\n",
    "    elif pos_certainty > 0.55:\n",
    "        print(f'{pos_certainty*100:2.4}% SENTIMENT    for     {text_in}')\n",
    "    else:\n",
    "        print(f'{pos_certainty*100:2.4}% UNKNOWN      for     {text_in}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', \"'m\", 'so', 'happy', 'tonight']]\n",
      "38.04% NO SENTIMENT for     I'm so happy tonight\n",
      "[['is', 'slightly', 'hungover', 'after', '@namesnorris', \"'s\", 'party', 'last', 'night', '.', 'great', 'night', '!']]\n",
      "59.47% SENTIMENT    for     Is slightly hungover after @namesnorris's party last night. Great night!\n",
      "[['summer', 'is', 'finnaly', 'here', '!', '!', '!', '!']]\n",
      "78.63% SENTIMENT    for     SUMMER is FINNALY here!!!!\n",
      "[['has', 'a', 'massive', 'headache', '.']]\n",
      "43.57% NO SENTIMENT for     has a massive headache.\n",
      "[['no', 'food', 'on', 'the', 'table', '.']]\n",
      "6.558% NO SENTIMENT for     no food on the table.\n",
      "[['@josiew2012', 'thanks']]\n",
      "59.69% SENTIMENT    for     @josiew2012 thanks\n",
      "[['bloody', 'damn', 'damness', '!']]\n",
      "10.39% NO SENTIMENT for     Bloody damn damness!\n",
      "[['@taylor510ce', 'i', 'love', 'you', '!', ' ', 'hope', 'you', 'have', 'a', 'better', 'day', 'today']]\n",
      "59.69% SENTIMENT    for     @Taylor510CE I love you!  Hope you have a better day today\n"
     ]
    }
   ],
   "source": [
    "textos = [\n",
    "    \"I'm so happy tonight\",\n",
    "    \"Is slightly hungover after @namesnorris's party last night. Great night!\",\n",
    "    \"SUMMER is FINNALY here!!!!\",\n",
    "    \"has a massive headache.\",\n",
    "    \"no food on the table.\",\n",
    "    \"@josiew2012 thanks\",\n",
    "    \"Bloody damn damness!\",\n",
    "    \"@Taylor510CE I love you!  Hope you have a better day today\"\n",
    "    ]\n",
    "\n",
    "for t in textos:\n",
    "    process_text(t, txt_field, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'m\", 'so', 'happy', 'tonight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.Size([5, 1]) from 20 chars / 5 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  2],\n",
       "        [  0],\n",
       "        [ 20],\n",
       "        [127],\n",
       "        [129]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'slightly', 'hungover', 'after', '@namesnorris', \"'s\", 'party', 'last', 'night', '.', 'great', 'night', '!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.Size([13, 1]) from 72 chars / 13 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  10],\n",
       "        [1859],\n",
       "        [2597],\n",
       "        [ 161],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [ 297],\n",
       "        [  98],\n",
       "        [  78],\n",
       "        [   0],\n",
       "        [ 105],\n",
       "        [  78],\n",
       "        [   0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summer', 'is', 'finnaly', 'here', '!', '!', '!', '!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.Size([8, 1]) from 26 chars / 8 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  242],\n",
       "        [   10],\n",
       "        [23393],\n",
       "        [   92],\n",
       "        [    0],\n",
       "        [    0],\n",
       "        [    0],\n",
       "        [    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has', 'a', 'massive', 'headache', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.Size([5, 1]) from 23 chars / 5 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 107],\n",
       "        [   5],\n",
       "        [1918],\n",
       "        [ 497],\n",
       "        [   0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'food', 'on', 'the', 'table', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.Size([6, 1]) from 21 chars / 6 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  41],\n",
       "        [ 375],\n",
       "        [  18],\n",
       "        [   4],\n",
       "        [1874],\n",
       "        [   0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in textos:\n",
    "    tok = [t2.text.lower() for t2 in nlp(t)]\n",
    "    print(tok)\n",
    "    tmp = txt_field.numericalize(([tok], 1))\n",
    "    display(f'{tmp[0].size()} from {len(t)} chars / {len(tok)} words')\n",
    "    display(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_field.vocab.itos[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(tok)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field.numericalize??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
