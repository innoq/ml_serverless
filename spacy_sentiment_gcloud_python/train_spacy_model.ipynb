{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import math\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding, decaying\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "n_iter = 20\n",
    "data_path = './data'\n",
    "train_data_url = 'https://raw.githubusercontent.com/uds-lsv/GermEval-2018-Data/master/germeval2018.training.txt'\n",
    "train_data_path = f'{data_path}/germeval2018.training.txt'\n",
    "model_ext = '_100d_100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    if not os.path.exists(data_path):\n",
    "        os.mkdir(data_path)\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise FileExistsError('data path exists, but is not directory (or not accessible)')\n",
    "    urlretrieve(train_data_url, train_data_path)\n",
    "    \n",
    "    \n",
    "def get_data(validation_ratio=0.1):\n",
    "    df_trn = pd.read_csv(train_data_path, sep='\\t', header=None, names=['text', 'bin', 'detail']).drop('detail', axis=1)\n",
    "    \n",
    "    # split into trn and validation\n",
    "    idx = np.arange(len(df_trn))\n",
    "    np.random.shuffle(idx)\n",
    "    val_size = math.ceil(len(df_trn) * validation_ratio)\n",
    "    \n",
    "    val_df = df_trn.iloc[idx[:val_size]]\n",
    "    trn_df = df_trn.iloc[idx[val_size:]]\n",
    "    \n",
    "    trn_labels = [{'OFFENSE': x == 'OFFENSE'} for x in trn_df['bin'].values]\n",
    "    val_labels = [{'OFFENSE': x == 'OFFENSE'} for x in val_df['bin'].values]\n",
    "    \n",
    "    return (tuple(trn_df['text'].values), trn_labels), (tuple(val_df['text'].values), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using examples (4508 training, 501 evaluation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@MGrosseBroemer Sprach nicht ein gewisser Herr Seehofer / #CSU davon, dass man die #Afd - Wähler zurückholen möchte? Macht sich ganz klasse, die potentiellen Wähler vorher erst mal noch gründlich zu beschimpfen...Sie haben wirklich ALLES verstanden! |LBR| @Beatrix_vStorch @cducsubt @AfDimBundestag',\n",
       "  {'cats': {'OFFENSE': False}}),\n",
       " ('Der ewige Kanzler und große Europäer geht. Seine Verdienste um die Deutsche Einheit bleiben. Wir trauern um Helmut Kohl.',\n",
       "  {'cats': {'OFFENSE': False}})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data()\n",
    "(train_texts, train_cats), (eval_texts, eval_cats) = get_data(validation_ratio=0.1)\n",
    "\n",
    "print(\"Using examples ({} training, {} evaluation)\".format(len(train_texts), len(eval_texts)))\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))\n",
    "eval_data = list(zip(eval_texts, eval_cats))\n",
    "train_data[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an adapted, vectorized model for german text on command-line with:\n",
    "\n",
    "```\n",
    "wget http://4530.hostserv.eu/resources/embed_tweets_de_100D_fasttext.zip\n",
    "python -m spacy init-model de data/de_vec_twitter_100d_100k --vectors-loc embed_tweets_de_100D_fasttext.zip --prune-vectors 100000```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline ['textcat']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(f'data/de_vec_twitter{model_ext}')\n",
    "\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "textcat.add_label('OFFENSE')\n",
    "\n",
    "print(f'pipeline {nlp.pipe_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%xmode Verbose\n",
    "def train_model(nlp, train_data, eval_data):\n",
    "    \n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "        optimizer.max_grad_norm = 0.6\n",
    "        print(\"Training the model...\")\n",
    "        print('\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "        best_f = 0\n",
    "        last_f = 0\n",
    "        n_iter_nogain = 0\n",
    "        dropout = decaying(0.45, 0.2, 1e-4)\n",
    "        eval_texts, eval_cats = zip(*eval_data)\n",
    "        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(1, 8, 1.01))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=next(dropout), losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, eval_texts, eval_cats)\n",
    "            if scores['textcat_f'] > best_f:\n",
    "                best_f = scores['textcat_f']\n",
    "                n_iter_nogain = 0\n",
    "            #elif scores['textcat_f'] > last_f:\n",
    "            #    n_iter_nogain = 0\n",
    "            else:\n",
    "                n_iter_nogain += 1\n",
    "            last_f = scores['textcat_f']\n",
    "            print('{4}\\t{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "                  .format(losses['textcat'], scores['textcat_p'],\n",
    "                          scores['textcat_r'], scores['textcat_f'], i))\n",
    "            if n_iter_nogain > 3:\n",
    "                print('early stopping')\n",
    "                break\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\tLOSS \t  P  \t  R  \t  F  \n",
      "0\t173.222\t0.690\t0.195\t0.304\n",
      "1\t121.184\t0.658\t0.336\t0.444\n",
      "2\t87.401\t0.663\t0.423\t0.516\n",
      "3\t62.140\t0.647\t0.517\t0.575\n",
      "4\t46.587\t0.625\t0.503\t0.558\n",
      "5\t34.685\t0.625\t0.503\t0.558\n",
      "6\t27.226\t0.646\t0.564\t0.602\n",
      "7\t22.280\t0.640\t0.584\t0.611\n",
      "8\t16.681\t0.638\t0.557\t0.595\n",
      "9\t14.156\t0.619\t0.557\t0.587\n",
      "10\t11.124\t0.600\t0.564\t0.581\n",
      "11\t10.292\t0.627\t0.597\t0.612\n",
      "12\t8.654\t0.610\t0.577\t0.593\n",
      "13\t6.837\t0.607\t0.591\t0.599\n",
      "14\t5.844\t0.613\t0.584\t0.598\n",
      "15\t4.416\t0.622\t0.597\t0.610\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = train_model(nlp, train_data, eval_data)\n",
    "with nlp.use_params(optimizer.averages):\n",
    "    nlp.to_disk(f'data/de_cat{model_ext}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load(f'data/de_cat{model_ext}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233520150184631"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp2(\"Warum sind die Geier so gierig\")\n",
    "doc.cats['OFFENSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
